{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-aberdeen",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Engineering\n",
    "> Cleaning and feature engineering based on the insights gained from the previous step on EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e441aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "from pandas import DataFrame\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from DSAI_proj.extract import *\n",
    "from DSAI_proj.eda import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import concurrent\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea105654",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-artwork",
   "metadata": {},
   "source": [
    "The first step will be to process the categorical variables of the dataset. In this case, we have genres as a categorical variable. We will use the MultiLabelBinarizer from scikit-learn to one-hot-encode the movie genres. This will create additional columns in our DataFrame, each corresponding to a separate genre type. We will reuse the clean_genre function used in the EDA section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/l94l89eMmFKh7na2a1u5q67VgNx.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>/u0zMKKpEdDWpOKmFW2sLbKKICJH.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>/5aXp2s4l6g5PcMMesIj63mx8hmJ.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  adult                     backdrop_path belongs_to_collection  \\\n",
       "0           0  False  /hQ4pYsIbP22TMXOUdSfC2mjWrO0.jpg                   NaN   \n",
       "1           1  False  /l94l89eMmFKh7na2a1u5q67VgNx.jpg                   NaN   \n",
       "2           2  False  /u0zMKKpEdDWpOKmFW2sLbKKICJH.jpg                   NaN   \n",
       "3           3  False  /5aXp2s4l6g5PcMMesIj63mx8hmJ.jpg                   NaN   \n",
       "4           4  False                               NaN                   NaN   \n",
       "\n",
       "   ...  Mystery Romance  Science Fiction Thriller  \n",
       "0  ...        0       0                0        0  \n",
       "1  ...        0       0                0        0  \n",
       "2  ...        0       0                0        0  \n",
       "3  ...        0       0                0        1  \n",
       "4  ...        0       0                0        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_genre(df=movies)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-bermuda",
   "metadata": {},
   "source": [
    "Next, we will need to extract the images into a separate directory. This will allow for easier access during the training stage. The following codes help us to extract the backdrop and poster images from their urls to separate directories. We can multithread this function as well as it involves multiple IO operations. Additionally, as some examples will not have images, we will drop these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def req_image(url: str, save_path: str, id_num: int):\n",
    "    req_url = f\"https://image.tmdb.org/t/p/original{url}\"\n",
    "    response = requests.get(req_url)\n",
    "    if response.status_code == 200:\n",
    "        fname = os.path.join(save_path, f\"{id_num}.jpg\")\n",
    "        with open(fname, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "            return None\n",
    "    return id_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def extract_images_threaded(df: DataFrame,\n",
    "                            cur_path: str,\n",
    "                            img_type: list,\n",
    "                            max_threads: int) -> tuple:\n",
    "    max_threads = max_threads if max_threads < len(df) else len(df)\n",
    "    problem_ids = []\n",
    "    for itype in img_type:\n",
    "        save_path = os.path.join(cur_path, f\"{itype}_img\")\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            pids = [id_num for cnt, url in enumerate(df[f\"{itype}_path\"]) if (id_num := executor.submit(req_image, url, save_path, df.iloc[cnt]['id']).result()) is not None]\n",
    "        problem_ids.extend(pids)\n",
    "        print(f\"{itype} images written successfully!\")\n",
    "    problem_ids = set(problem_ids)\n",
    "    df = df[~df['id'].isin(problem_ids)]\n",
    "    return df, problem_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poster images written successfully!\n",
      "backdrop images written successfully!\n",
      "Dropped the following rows due to missing images: {8, 9}\n"
     ]
    }
   ],
   "source": [
    "df, problem_ids = extract_images_threaded(df=df, cur_path=\".\", img_type=[\"poster\", \"backdrop\"], max_threads=10)\n",
    "print(f\"Dropped the following rows due to missing images: {problem_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-server",
   "metadata": {},
   "source": [
    "Lastly, from the previous notebook on EDA, we have already identified the relevant and irrelevant features required for our tagline prediction task. We will now drop the columns or features that are irrelevant. We can also include the image url paths to be dropped as we have already extracted the necessary images into a separate folder. Additionally, we also feature engineer based on the release dates to split that column into year, month and day separately. This generally allows models to process such meta information better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "def split_datetime(df: DataFrame,\n",
    "                   date_col: str) -> DataFrame:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], format='%Y-%m-%d')\n",
    "    df[f\"{date_col}_year\"] = df[date_col].dt.year\n",
    "    df[f\"{date_col}_month\"] = df[date_col].dt.month\n",
    "    df[f\"{date_col}_day\"] = df[date_col].dt.day\n",
    "    df.drop(date_col, inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def drop_col(data: DataFrame,\n",
    "             irrelevant_cols: list) -> DataFrame:\n",
    "    df = data.drop(irrelevant_cols,axis = 1)\n",
    "    df = split_datetime(df=df, date_col=\"release_date\")\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>...</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>release_date_year</th>\n",
       "      <th>release_date_month</th>\n",
       "      <th>release_date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Taisto Kasurinen is a Finnish coal miner whose...</td>\n",
       "      <td></td>\n",
       "      <td>Ariel</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>An episode in the life of Nikander, a garbage ...</td>\n",
       "      <td></td>\n",
       "      <td>Shadows in Paradise</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>It's Ted the Bellhop's first night on the job....</td>\n",
       "      <td>Twelve outrageous guests. Four scandalous requ...</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>While racing to a boxing match, Frank, Mike, J...</td>\n",
       "      <td>Don't move. Don't whisper. Don't even breathe.</td>\n",
       "      <td>Judgment Night</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1993</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>Princess Leia is captured and held hostage by ...</td>\n",
       "      <td>A long time ago in a galaxy far, far away...</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           overview  \\\n",
       "0   2  Taisto Kasurinen is a Finnish coal miner whose...   \n",
       "1   3  An episode in the life of Nikander, a garbage ...   \n",
       "2   5  It's Ted the Bellhop's first night on the job....   \n",
       "3   6  While racing to a boxing match, Frank, Mike, J...   \n",
       "6  11  Princess Leia is captured and held hostage by ...   \n",
       "\n",
       "                                             tagline                title  \\\n",
       "0                                                                   Ariel   \n",
       "1                                                     Shadows in Paradise   \n",
       "2  Twelve outrageous guests. Four scandalous requ...           Four Rooms   \n",
       "3     Don't move. Don't whisper. Don't even breathe.       Judgment Night   \n",
       "6       A long time ago in a galaxy far, far away...            Star Wars   \n",
       "\n",
       "   Action  ...  Science Fiction  Thriller  release_date_year  \\\n",
       "0       0  ...                0         0               1988   \n",
       "1       0  ...                0         0               1986   \n",
       "2       0  ...                0         0               1995   \n",
       "3       1  ...                0         1               1993   \n",
       "6       1  ...                1         0               1977   \n",
       "\n",
       "   release_date_month  release_date_day  \n",
       "0                  10                21  \n",
       "1                  10                17  \n",
       "2                  12                 9  \n",
       "3                  10                15  \n",
       "6                   5                25  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irrelevant_columns = ['belongs_to_collection','homepage','imdb_id','production_companies','popularity','original_language','original_title','revenue','runtime','spoken_languages','status','video','vote_average','vote_count','production_countries','budget', 'poster_path', 'backdrop_path']\n",
    "df = drop_col(data=df, irrelevant_cols=irrelevant_columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-violation",
   "metadata": {},
   "source": [
    "The text will not require as much preprocessing as we will be using transformer based models to deal with the text data. We will look into that in greater detail later. Now that we are done with the basic preprocessing and feature engineering, we can finally create our train, validation and test splits in separate csv files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-indonesian",
   "metadata": {},
   "source": [
    "Looking at the first 5 rows of the cleaned dataset, we easily see that some example taglines (under the tagline column) are missing. We'll need to separate these examples into a separate csv file as they do not have labels. Additionally, we can create our train, validation and test datasets concurrently and save them into separate csv files. This helps reproducibility later on. We also print the relative proportions of each dataset to see if we will need to redo the extraction process above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def create_splits(df: DataFrame,\n",
    "                  label: str,\n",
    "                  splits: list,\n",
    "                  seed: int,\n",
    "                  keep_missing: bool,\n",
    "                  save_path: str = \".\"):\n",
    "\n",
    "    assert len(splits) == 2, \"Train, validation and test splits must be provided, please provide 2 of them as fractions.\"\n",
    "    if keep_missing:\n",
    "        unlabelled_df = df[df[label] == '']\n",
    "        unlabelled_df.to_csv(os.path.join(save_path, \"tagless.csv\"))\n",
    "        print(f\"Tagless set size: {len(unlabelled_df)}\")\n",
    "        print(\"Tagless dataset created!\")\n",
    "    labelled_df = df[df[label] != '']\n",
    "    df_size = len(labelled_df)\n",
    "    labelled_df = shuffle(labelled_df, random_state=seed)\n",
    "    labelled_df.reset_index(inplace=True, drop=True)\n",
    "    valid_start, test_start = int(df_size*splits[0]), int(df_size*splits[0] + df_size*splits[1])\n",
    "    train_df = labelled_df.iloc[:valid_start]\n",
    "    valid_df = labelled_df.iloc[valid_start:test_start]\n",
    "    test_df = labelled_df[test_start:]\n",
    "    print(f\"Train set size: {len(train_df)}\\nValid set size: {len(valid_df)}\\nTest set size: {len(test_df)}\")\n",
    "    train_df.to_csv(os.path.join(save_path, \"train.csv\"), index=False)\n",
    "    valid_df.to_csv(os.path.join(save_path, \"valid.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(save_path, \"test.csv\"), index=False)\n",
    "    print(\"Train, Validation and Test datasets created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagless set size: 2\n",
      "Tagless dataset created!\n",
      "Train set size: 7\n",
      "Valid set size: 2\n",
      "Test set size: 2\n",
      "Train, Validation and Test datasets created!\n"
     ]
    }
   ],
   "source": [
    "splits = [0.7, 0.15]\n",
    "label = \"tagline\"\n",
    "seed = 42\n",
    "create_splits(df=df,\n",
    "              label=label,\n",
    "              splits=splits,\n",
    "              seed=seed,\n",
    "              keep_missing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
