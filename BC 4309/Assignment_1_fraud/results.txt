    0    1    2    3         4         5         6         7         8    9
0    1.0  0.0  0.0  0.0  0.000984  0.013158  0.025407  0.000000  0.000000  0.0
1    1.0  0.0  0.0  0.0  0.000186  0.001643  0.003072  0.000000  0.000000  0.0
2    1.0  0.0  0.0  0.0  0.001167  0.003214  0.004737  0.000000  0.000000  0.0
3    1.0  0.0  0.0  0.0  0.000782  0.004165  0.007298  0.000000  0.000000  0.0
4    1.0  0.0  0.0  0.0  0.000711  0.014168  0.027910  0.000000  0.000000  0.0
5    1.0  0.0  0.0  0.0  0.000786  0.013618  0.026664  0.000000  0.000000  0.0
6    1.0  0.0  0.0  0.0  0.000402  0.000207  0.000000  0.000000  0.000000  0.0
7    0.0  1.0  0.0  0.0  0.000534  0.003227  0.005767  0.003220  0.002105  0.0
8    0.0  1.0  0.0  0.0  0.000964  0.000345  0.000000  0.000834  0.008241  0.0
9    1.0  0.0  0.0  0.0  0.000310  0.001606  0.002801  0.000000  0.000000  0.0
10   1.0  0.0  0.0  0.0  0.000256  0.000392  0.000398  0.000000  0.000000  0.0
11   1.0  0.0  0.0  0.0  0.001163  0.000783  0.000000  0.000000  0.000000  0.0
12   1.0  0.0  0.0  0.0  0.000410  0.038921  0.079118  0.000000  0.000000  0.0
13   0.0  0.0  0.0  1.0  0.022913  0.001185  0.000000  0.000391  0.002687  0.0
14   1.0  0.0  0.0  0.0  0.000156  0.000035  0.000000  0.000000  0.000000  0.0
15   1.0  0.0  0.0  0.0  0.000116  0.001636  0.003170  0.000000  0.000000  0.0
16   1.0  0.0  0.0  0.0  0.000067  0.001170  0.002291  0.000000  0.000000  0.0
17   0.0  0.0  1.0  0.0  0.021531  0.000055  0.000000  0.001724  0.000000  0.0
18   1.0  0.0  0.0  0.0  0.000137  0.001071  0.001978  0.000000  0.000000  0.0
19   0.0  1.0  0.0  0.0  0.000930  0.000874  0.000316  0.002293  0.000881  0.0
20   0.0  1.0  0.0  0.0  0.000107  0.000141  0.000119  0.000794  0.000000  0.0
21   1.0  0.0  0.0  0.0  0.000388  0.005247  0.010140  0.000000  0.000000  0.0
22   0.0  0.0  1.0  0.0  0.031169  0.000838  0.000000  0.000482  0.141851  0.0
23   1.0  0.0  0.0  0.0  0.000606  0.000034  0.000000  0.000000  0.000000  0.0
24   1.0  0.0  0.0  0.0  0.000948  0.009009  0.016962  0.000000  0.000000  0.0
25   1.0  0.0  0.0  0.0  0.000801  0.000848  0.000469  0.000000  0.000000  0.0
26   1.0  0.0  0.0  0.0  0.000890  0.000229  0.000000  0.000000  0.000000  0.0
27   1.0  0.0  0.0  0.0  0.000992  0.000000  0.000000  0.000000  0.000000  0.0
28   1.0  0.0  0.0  0.0  0.000345  0.000000  0.000000  0.000000  0.000000  0.0
29   1.0  0.0  0.0  0.0  0.000421  0.000000  0.000000  0.000000  0.000000  0.0
..   ...  ...  ...  ...       ...       ...       ...       ...       ...  ...
470  0.0  0.0  1.0  0.0  0.000210  0.000162  0.000000  0.000000  0.000000  1.0
471  0.0  0.0  0.0  1.0  0.000210  0.000162  0.000000  0.008648  0.005979  1.0
472  0.0  0.0  1.0  0.0  0.193392  0.000000  0.000000  0.098671  0.167857  1.0
473  0.0  0.0  1.0  0.0  0.031342  0.024239  0.000000  0.000000  0.005111  1.0
474  0.0  0.0  0.0  1.0  0.031342  0.024239  0.000000  0.052893  0.053728  1.0
475  0.0  0.0  1.0  0.0  0.001246  0.000964  0.000000  0.000000  0.000000  1.0
476  0.0  0.0  0.0  1.0  0.001246  0.000964  0.000000  0.002149  0.002109  1.0
477  0.0  0.0  1.0  0.0  0.001947  0.001506  0.000000  0.000000  0.000000  1.0
478  0.0  0.0  0.0  1.0  0.001947  0.001506  0.000000  0.000000  0.001016  1.0
479  0.0  0.0  1.0  0.0  0.396413  0.306574  0.000000  0.000000  0.000000  1.0
480  0.0  0.0  0.0  1.0  0.396413  0.306574  0.000000  0.147032  0.303146  1.0
481  0.0  0.0  1.0  0.0  0.104165  0.080558  0.000000  0.000000  0.000000  1.0
482  0.0  0.0  0.0  1.0  0.104165  0.080558  0.000000  0.004053  0.057090  1.0
483  0.0  0.0  1.0  0.0  0.206647  0.159814  0.000000  0.000000  0.004236  1.0
484  0.0  0.0  0.0  1.0  0.206647  0.159814  0.000000  0.014950  0.161643  1.0
485  0.0  0.0  0.0  1.0  0.014967  0.000000  0.000000  0.003395  0.010112  1.0
486  0.0  0.0  1.0  0.0  0.000201  0.000155  0.000000  0.000000  0.000000  1.0
487  0.0  0.0  0.0  1.0  0.000201  0.000155  0.000000  0.009986  0.013089  1.0
488  0.0  0.0  0.0  1.0  0.022205  0.000000  0.000000  0.000229  0.011739  1.0
489  0.0  0.0  1.0  0.0  0.000868  0.000671  0.000000  0.000000  0.000000  1.0
490  0.0  0.0  0.0  1.0  0.000868  0.000671  0.000000  0.017304  0.012197  1.0
491  0.0  0.0  1.0  0.0  0.000041  0.000032  0.000000  0.000000  0.011790  1.0
492  0.0  0.0  0.0  1.0  0.000041  0.000032  0.000000  0.069044  0.056124  1.0
493  0.0  0.0  1.0  0.0  0.004838  0.003741  0.000000  0.000000  0.000000  1.0
494  0.0  0.0  0.0  1.0  0.004838  0.003741  0.000000  0.028808  0.034353  1.0
495  0.0  0.0  1.0  0.0  0.402267  0.311101  0.000000  0.000000  0.000000  1.0
496  0.0  0.0  0.0  1.0  0.402267  0.311101  0.000000  0.006159  0.211652  1.0
497  0.0  0.0  0.0  1.0  0.045486  0.000000  0.000000  0.000000  0.023729  1.0
498  0.0  0.0  1.0  0.0  0.116150  0.089827  0.000000  0.000000  0.000000  1.0
499  0.0  0.0  0.0  1.0  0.116150  0.089827  0.000000  0.024521  0.081648  1.0

[500 rows x 10 columns]
                0           1           2           3             4  \
count  500.000000  500.000000  500.000000  500.000000  5.000000e+02   
mean     0.366000    0.046000    0.212000    0.376000  2.535193e-02   
std      0.482192    0.209695    0.409134    0.484865  8.770843e-02   
min      0.000000    0.000000    0.000000    0.000000  8.730000e-07   
25%      0.000000    0.000000    0.000000    0.000000  4.313295e-04   
50%      0.000000    0.000000    0.000000    0.000000  1.585232e-03   
75%      1.000000    0.000000    0.000000    1.000000  1.411770e-02   
max      1.000000    1.000000    1.000000    1.000000  1.000000e+00   

                5           6           7           8           9  
count  500.000000  500.000000  500.000000  500.000000  500.000000  
mean     0.022875    0.017365    0.019291    0.045696    0.300000  
std      0.089346    0.111858    0.072230    0.155431    0.458717  
min      0.000000    0.000000    0.000000    0.000000    0.000000  
25%      0.000000    0.000000    0.000000    0.000000    0.000000  
50%      0.000874    0.000000    0.000000    0.000000    0.000000  
75%      0.004208    0.001200    0.009426    0.008888    1.000000  
max      1.000000    1.000000    1.000000    1.000000    1.000000  
Regression
================================
[[187  17]
 [ 33  63]]
Regression TrainSet: Accurarcy 83.33%
================================
[[139   7]
 [ 22  32]]
Regression Testset: Accurarcy 85.50%
================================
================================
================================
Decision Tree
================================
[[204   0]
 [  0  96]]
Decsion Tree TrainSet: Accurarcy 100.00%
================================
[[137   9]
 [  0  54]]
Decision Tree Testset: Accurarcy 95.50%
================================
================================
================================
Random Forest
================================
[[203   1]
 [ 34  62]]
Random Forest TrainSet: Accurarcy 88.33%
================================
[[146   0]
 [ 25  29]]
Random Forest Testset: Accurarcy 87.50%
================================
================================
================================
Xgboost
================================
C:\Users\graez\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
[[204   0]
 [  0  96]]
Xgboost TrainSet: Accurarcy 100.00%
==================================
Xgboost on testset confusion matrix
[[143   3]
 [  0  54]]
Xgboost on TestSet: Accuracy 98.50%
==================================
10/10 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8033
Neural Network Trainset: 
accuracy: 80.33%
==================================
==================================
Neural Network on testset confusion matrix
[[136  10]
 [ 30  24]]
Neural Network on TestSet: Accuracy 80.00%