{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ce1il03S6_Te",
    "outputId": "a2fa7d02-3221-4c15-ee7c-98d67e078d82",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1     2     3      4     5      6     7    8\n",
      "0     6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0  1.0\n",
      "1     1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0  0.0\n",
      "2     8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  1.0\n",
      "3     1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  0.0\n",
      "4     0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0\n",
      "..    ...    ...   ...   ...    ...   ...    ...   ...  ...\n",
      "763  10.0  101.0  76.0  48.0  180.0  32.9  0.171  63.0  0.0\n",
      "764   2.0  122.0  70.0  27.0    0.0  36.8  0.340  27.0  0.0\n",
      "765   5.0  121.0  72.0  23.0  112.0  26.2  0.245  30.0  0.0\n",
      "766   1.0  126.0  60.0   0.0    0.0  30.1  0.349  47.0  1.0\n",
      "767   1.0   93.0  70.0  31.0    0.0  30.4  0.315  23.0  0.0\n",
      "\n",
      "[768 rows x 9 columns]\n",
      "                0           1           2  ...           6           7           8\n",
      "count  768.000000  768.000000  768.000000  ...  768.000000  768.000000  768.000000\n",
      "mean     3.845052  120.894531   69.105469  ...    0.471876   33.240885    0.348958\n",
      "std      3.369578   31.972618   19.355807  ...    0.331329   11.760232    0.476951\n",
      "min      0.000000    0.000000    0.000000  ...    0.078000   21.000000    0.000000\n",
      "25%      1.000000   99.000000   62.000000  ...    0.243750   24.000000    0.000000\n",
      "50%      3.000000  117.000000   72.000000  ...    0.372500   29.000000    0.000000\n",
      "75%      6.000000  140.250000   80.000000  ...    0.626250   41.000000    1.000000\n",
      "max     17.000000  199.000000  122.000000  ...    2.420000   81.000000    1.000000\n",
      "\n",
      "[8 rows x 9 columns]\n",
      "Regression\n",
      "================================\n",
      "[[274  31]\n",
      " [ 62  93]]\n",
      "Regression TrainSet: Accurarcy 79.78%\n",
      "================================\n",
      "[[172  23]\n",
      " [ 53  60]]\n",
      "Regression Testset: Accurarcy 75.32%\n",
      "================================\n",
      "================================\n",
      "================================\n",
      "Decision Tree\n",
      "================================\n",
      "[[305   0]\n",
      " [  0 155]]\n",
      "Decsion Tree TrainSet: Accurarcy 100.00%\n",
      "================================\n",
      "[[137  58]\n",
      " [ 55  58]]\n",
      "Decision Tree Testset: Accurarcy 63.31%\n",
      "================================\n",
      "================================\n",
      "================================\n",
      "Random Forest\n",
      "================================\n",
      "[[290  15]\n",
      " [ 96  59]]\n",
      "Random Forest TrainSet: Accurarcy 75.87%\n",
      "================================\n",
      "[[184  11]\n",
      " [ 80  33]]\n",
      "Random Forest Testset: Accurarcy 70.45%\n",
      "================================\n",
      "================================\n",
      "================================\n",
      "Xgboost\n",
      "================================\n",
      "[[297   8]\n",
      " [ 21 134]]\n",
      "Xgboost TrainSet: Accurarcy 93.70%\n",
      "==================================\n",
      "Xgboost on testset confusion matrix\n",
      "[[164  31]\n",
      " [ 48  65]]\n",
      "Xgboost on TestSet: Accuracy 74.35%\n",
      "==================================\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7326\n",
      "Neural Network Trainset: \n",
      "accuracy: 73.26%\n",
      "==================================\n",
      "==================================\n",
      "Neural Network on testset confusion matrix\n",
      "[[152  43]\n",
      " [ 67  46]]\n",
      "Neural Network on TestSet: Accuracy 64.29%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "Y_position = 8\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"Diabetes (Edited).csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df)\n",
    "\t# summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "X = dataset[:,0:Y_position]\n",
    "Y = dataset[:,Y_position]\n",
    "# create model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=2020)\n",
    "\n",
    "#scaling to around -2 to 2 (Z)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "#Model 1 : linear regression\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "#intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
    "#verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "linear_classifier = linear_model.LogisticRegression(random_state=123)\n",
    "linear_classifier.fit(scaled_X_train, y_train)\n",
    "y_pred_train1 = linear_classifier.predict(scaled_X_train)\n",
    "cm1_train = confusion_matrix(y_train,y_pred_train1)\n",
    "print(\"Regression\")\n",
    "print(\"================================\")\n",
    "print(cm1_train)\n",
    "acc_train1 = (cm1_train[0,0] + cm1_train[1,1]) / sum(sum(cm1_train))\n",
    "print(\"Regression TrainSet: Accurarcy %.2f%%\" % (acc_train1*100))\n",
    "print(\"================================\")\n",
    "y_pred1 = linear_classifier.predict(scaled_X_test)\n",
    "cm1 = confusion_matrix(y_test,y_pred1)\n",
    "print(cm1)\n",
    "acc1 = (cm1[0,0] + cm1[1,1]) / sum(sum(cm1))\n",
    "print(\"Regression Testset: Accurarcy %.2f%%\" % (acc1*100))\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "\n",
    "\n",
    "#Model 2: decision tree\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(scaled_X_train, y_train)\n",
    "y_pred_train2 = clf.predict(scaled_X_train)\n",
    "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
    "print(\"Decision Tree\")\n",
    "print(\"================================\")\n",
    "print(cm2_train)\n",
    "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
    "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
    "print(\"================================\")\n",
    "y_pred2 = clf.predict(scaled_X_test)\n",
    "cm2 = confusion_matrix(y_test,y_pred2)\n",
    "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
    "print(cm2)\n",
    "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "\n",
    "\n",
    "#Model 3 random forest\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
    "#min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
    "\n",
    "model3 = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "model3.fit(scaled_X_train, y_train)\n",
    "y_predicted3 = model3.predict(scaled_X_test)\n",
    "\n",
    "y_pred_train3 = model3.predict(scaled_X_train)\n",
    "cm3_train = confusion_matrix(y_train,y_pred_train3)\n",
    "print(\"Random Forest\")\n",
    "print(\"================================\")\n",
    "print(cm3_train)\n",
    "acc_train3 = (cm3_train[0,0] + cm3_train[1,1]) / sum(sum(cm3_train))\n",
    "print(\"Random Forest TrainSet: Accurarcy %.2f%%\" % (acc_train3*100))\n",
    "print(\"================================\")\n",
    "y_pred3 = model3.predict(scaled_X_test)\n",
    "cm_test3 = confusion_matrix(y_test,y_pred3)\n",
    "print(cm_test3)\n",
    "acc_test3 = (cm_test3[0,0] + cm_test3[1,1]) / sum(sum(cm_test3))\n",
    "print(\"Random Forest Testset: Accurarcy %.2f%%\" % (acc_test3*100))\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "print(\"================================\")\n",
    "\n",
    "#Model 4: XGBoost\n",
    "\n",
    "print(\"Xgboost\")\n",
    "print(\"================================\")\n",
    "#class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, \n",
    "#subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "#max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, \n",
    "#n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "model4 = GradientBoostingClassifier(random_state=0)\n",
    "model4.fit(scaled_X_train, y_train)\n",
    "y_pred_train4 = model4.predict(scaled_X_train)\n",
    "cm4_train = confusion_matrix(y_train,y_pred_train4)\n",
    "print(cm4_train)\n",
    "acc_train4 = (cm4_train[0,0] + cm4_train[1,1]) / sum(sum(cm4_train))\n",
    "print(\"Xgboost TrainSet: Accurarcy %.2f%%\" % (acc_train4*100))\n",
    "predictions = model4.predict(scaled_X_test)\n",
    "y_pred4 = (predictions > 0.5)\n",
    "y_pred4 =y_pred4*1 #convert to 0,1 instead of True False\n",
    "cm4 = confusion_matrix(y_test, y_pred4)\n",
    "print(\"==================================\")\n",
    "print(\"Xgboost on testset confusion matrix\")\n",
    "print(cm4)\n",
    "acc4 = (cm4[0,0] + cm4[1,1]) / sum(sum(cm4))\n",
    "print(\"Xgboost on TestSet: Accuracy %.2f%%\" % (acc4*100))\n",
    "print(\"==================================\")\n",
    "\n",
    "#Model 5: neural network\n",
    "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=Y_position, activation='relu'))\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile mode\n",
    "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, y_train)\n",
    "#print(scores)\n",
    "print(\"Neural Network Trainset: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "predictions5 = model.predict(X_test)\n",
    "#print(predictions)\n",
    "#print('predictions shape:', predictions.shape)\n",
    "\n",
    "y_pred5 = (predictions5 > 0.5)\n",
    "y_pred5 = y_pred5*1 #convert to 0,1 instead of True False\n",
    "cm5 = confusion_matrix(y_test, y_pred5)\n",
    "print(\"==================================\")\n",
    "print(\"==================================\")\n",
    "print(\"Neural Network on testset confusion matrix\")\n",
    "print(cm5)\n",
    "\n",
    "## Get accurary from Confusion matrix\n",
    "## Position 0,0 and 1,1 are the correct predictions \n",
    "acc5 = (cm5[0,0] + cm5[1,1]) / sum(sum(cm5))\n",
    "print(\"Neural Network on TestSet: Accuracy %.2f%%\" % (acc5*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nSZP7j1dIBJ"
   },
   "source": [
    "## Feature importance\n",
    "\n",
    "### Feature importances with forests of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whZbWt0hdIBK",
    "outputId": "17d439b3-b9c0-4a25-830d-0798bd18ca67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature (Column index) 1 (0.307004)\n",
      "2. feature (Column index) 7 (0.237150)\n",
      "3. feature (Column index) 0 (0.129340)\n",
      "4. feature (Column index) 5 (0.129255)\n",
      "5. feature (Column index) 6 (0.069927)\n",
      "6. feature (Column index) 4 (0.055137)\n",
      "7. feature (Column index) 2 (0.044458)\n",
      "8. feature (Column index) 3 (0.027729)\n"
     ]
    }
   ],
   "source": [
    "RF = model3\n",
    "importances = RF.feature_importances_\n",
    "std = numpy.std([tree.feature_importances_ for tree in RF.estimators_],\n",
    "             axis=0)\n",
    "indices = numpy.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature (Column index) %s (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9XDQ8cSdIBV"
   },
   "source": [
    "## Permutation feature importance\n",
    "\n",
    "### Apply this to any sklearn model\n",
    "\n",
    "-Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but how important this feature is for a particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6gTnEJrdIBY",
    "outputId": "61fcdd14-b513-4062-891c-9f39564fc50e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1   : 0.129 +/- 0.020\n",
      "Feature 5   : 0.030 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    " from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(linear_classifier, scaled_X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "         print(f\"{'Feature '+str(i)+'   : '}\"\n",
    "               f\"{r.importances_mean[i]:.3f}\"\n",
    "               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuDxnhWGdIBh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
